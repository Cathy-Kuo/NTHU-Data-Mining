{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1867535, 2)\n",
      "(1867535, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>identification</th>\n",
       "      <th>_score</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0x28cc61</td>\n",
       "      <td>test</td>\n",
       "      <td>107</td>\n",
       "      <td>[]</td>\n",
       "      <td>@Habbo I've seen two separate colours of the e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0x29e452</td>\n",
       "      <td>train</td>\n",
       "      <td>809</td>\n",
       "      <td>[]</td>\n",
       "      <td>Huge Respectüñí @JohnnyVegasReal talking about l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0x2b3819</td>\n",
       "      <td>train</td>\n",
       "      <td>808</td>\n",
       "      <td>['spateradio', 'app']</td>\n",
       "      <td>Yoooo we hit all our monthly goals with the ne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0x2db41f</td>\n",
       "      <td>test</td>\n",
       "      <td>728</td>\n",
       "      <td>[]</td>\n",
       "      <td>@FoxNews @KellyannePolls No serious self respe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0x2a2acc</td>\n",
       "      <td>train</td>\n",
       "      <td>16</td>\n",
       "      <td>[]</td>\n",
       "      <td>@KIDSNTS @PICU_BCH @uhbcomms @BWCHBoss Well do...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tweet_id identification  _score               hashtags  \\\n",
       "0  0x28cc61           test     107                     []   \n",
       "1  0x29e452          train     809                     []   \n",
       "2  0x2b3819          train     808  ['spateradio', 'app']   \n",
       "3  0x2db41f           test     728                     []   \n",
       "4  0x2a2acc          train      16                     []   \n",
       "\n",
       "                                                text  \n",
       "0  @Habbo I've seen two separate colours of the e...  \n",
       "1  Huge Respectüñí @JohnnyVegasReal talking about l...  \n",
       "2  Yoooo we hit all our monthly goals with the ne...  \n",
       "3  @FoxNews @KellyannePolls No serious self respe...  \n",
       "4  @KIDSNTS @PICU_BCH @uhbcomms @BWCHBoss Well do...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_user = pd.read_csv(\"data_identification.csv\")\n",
    "tweets = pd.read_csv(\"tweet_.csv\", lineterminator='\\n')\n",
    "tweets = tweets.drop(columns=['Unnamed: 0'], axis=1)\n",
    "print(all_user.shape)\n",
    "print(tweets.shape)\n",
    "tweets.head()\n",
    "\n",
    "all_user = pd.merge(all_user,tweets, on=\"tweet_id\")\n",
    "all_user.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   tweet_id identification  _score  \\\n",
      "1  0x29e452          train     809   \n",
      "2  0x2b3819          train     808   \n",
      "4  0x2a2acc          train      16   \n",
      "5  0x2a8830          train     768   \n",
      "6  0x20b21d          train      70   \n",
      "\n",
      "                                            hashtags  \\\n",
      "1                                                 []   \n",
      "2                              ['spateradio', 'app']   \n",
      "4                                                 []   \n",
      "5  ['PUBG', 'GamersUnite', 'twitch', 'BeHealthy',...   \n",
      "6                       ['strength', 'bones', 'God']   \n",
      "\n",
      "                                                text  \n",
      "1  Huge Respectüñí @JohnnyVegasReal talking about l...  \n",
      "2  Yoooo we hit all our monthly goals with the ne...  \n",
      "4  @KIDSNTS @PICU_BCH @uhbcomms @BWCHBoss Well do...  \n",
      "5  Come join @ambushman27 on #PUBG while he striv...  \n",
      "6  @fanshixieen2014 Blessings!My #strength little...   (1455563, 5)\n",
      "    tweet_id identification  _score            hashtags  \\\n",
      "0   0x28cc61           test     107                  []   \n",
      "3   0x2db41f           test     728                  []   \n",
      "15  0x2466f6           test     491    ['womendrivers']   \n",
      "23  0x23f9e9           test      28  ['robbingmembers']   \n",
      "31  0x1fb4e1           test     925                  []   \n",
      "\n",
      "                                                 text  \n",
      "0   @Habbo I've seen two separate colours of the e...  \n",
      "3   @FoxNews @KellyannePolls No serious self respe...  \n",
      "15  Looking for a new car, and it says 1 lady owne...  \n",
      "23  @cineworld ‚Äúonly the brave‚Äù just out and fount...  \n",
      "31  Felt like total dog üí© going into open gym and ...   (411972, 5)\n"
     ]
    }
   ],
   "source": [
    "fliter = (all_user[\"identification\"] == 'train')\n",
    "df_train = all_user[fliter]\n",
    "fliter1 = (all_user[\"identification\"] == 'test')\n",
    "df_test = all_user[fliter1]\n",
    "print(df_train.head(), df_train.shape)\n",
    "print(df_test.head(), df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion = pd.read_csv(\"emotion.csv\")\n",
    "df_train = pd.merge(df_train,emotion, on=\"tweet_id\")\n",
    "df_train.iloc[4:100]\n",
    "\n",
    "df_train = df_train.drop(columns=['identification'],axis=1)\n",
    "df_test = df_test.drop(columns=['identification'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>_score</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>text</th>\n",
       "      <th>Full_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0x28cc61</td>\n",
       "      <td>107</td>\n",
       "      <td></td>\n",
       "      <td>@Habbo I've seen two separate colours of the e...</td>\n",
       "      <td>@Habbo I've seen two separate colours of the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0x2db41f</td>\n",
       "      <td>728</td>\n",
       "      <td></td>\n",
       "      <td>@FoxNews @KellyannePolls No serious self respe...</td>\n",
       "      <td>@FoxNews @KellyannePolls No serious self resp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0x2466f6</td>\n",
       "      <td>491</td>\n",
       "      <td>womendrivers</td>\n",
       "      <td>Looking for a new car, and it says 1 lady owne...</td>\n",
       "      <td>womendrivers Looking for a new car, and it say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0x23f9e9</td>\n",
       "      <td>28</td>\n",
       "      <td>robbingmembers</td>\n",
       "      <td>@cineworld ‚Äúonly the brave‚Äù just out and fount...</td>\n",
       "      <td>robbingmembers @cineworld ‚Äúonly the brave‚Äù jus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0x1fb4e1</td>\n",
       "      <td>925</td>\n",
       "      <td></td>\n",
       "      <td>Felt like total dog üí© going into open gym and ...</td>\n",
       "      <td>Felt like total dog üí© going into open gym and...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    tweet_id  _score        hashtags  \\\n",
       "0   0x28cc61     107                   \n",
       "3   0x2db41f     728                   \n",
       "15  0x2466f6     491    womendrivers   \n",
       "23  0x23f9e9      28  robbingmembers   \n",
       "31  0x1fb4e1     925                   \n",
       "\n",
       "                                                 text  \\\n",
       "0   @Habbo I've seen two separate colours of the e...   \n",
       "3   @FoxNews @KellyannePolls No serious self respe...   \n",
       "15  Looking for a new car, and it says 1 lady owne...   \n",
       "23  @cineworld ‚Äúonly the brave‚Äù just out and fount...   \n",
       "31  Felt like total dog üí© going into open gym and ...   \n",
       "\n",
       "                                            Full_text  \n",
       "0    @Habbo I've seen two separate colours of the ...  \n",
       "3    @FoxNews @KellyannePolls No serious self resp...  \n",
       "15  womendrivers Looking for a new car, and it say...  \n",
       "23  robbingmembers @cineworld ‚Äúonly the brave‚Äù jus...  \n",
       "31   Felt like total dog üí© going into open gym and...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "\n",
    "list_hash = df_train['hashtags'].tolist()\n",
    "for i in range(len(list_hash)):\n",
    "    if len(list_hash[i]) == 0:\n",
    "        list_hash[i]=None\n",
    "    else:\n",
    "        list_hash[i]=list_hash[i][1:len(list_hash[i])-2]\n",
    "        list_hash[i] = [word.strip(string.punctuation) for word in list_hash[i].split(\", \")]\n",
    "        list_hash[i] = ' '.join(list_hash[i])\n",
    "df_train['hashtags'] = list_hash\n",
    "df_train[\"Full_text\"] = df_train[\"hashtags\"] + \" \" + df_train[\"text\"]\n",
    "df_train.head()\n",
    "\n",
    "list_hash = df_test['hashtags'].tolist()\n",
    "for i in range(len(list_hash)):\n",
    "    if len(list_hash[i]) == 0:\n",
    "        list_hash[i]=None\n",
    "    else:\n",
    "        list_hash[i]=list_hash[i][1:len(list_hash[i])-2]\n",
    "        list_hash[i] = [word.strip(string.punctuation) for word in list_hash[i].split(\", \")]\n",
    "        list_hash[i] = ' '.join(list_hash[i])\n",
    "df_test['hashtags'] = list_hash\n",
    "df_test[\"Full_text\"] = df_test[\"hashtags\"] + \" \" + df_test[\"text\"]\n",
    "df_test.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "df_train = shuffle(df_train)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:484: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\"The parameter 'token_pattern' will not be used\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1455563, 3)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import nltk\n",
    "\n",
    "tfIdfVectorizer_1000 = TfidfVectorizer(max_features = 6000, tokenizer=nltk.word_tokenize, use_idf=True)\n",
    "\n",
    "tfIdfVectorizer_1000.fit(df_train['Full_text'])\n",
    "\n",
    "t = tfIdfVectorizer_1000.transform(df_train['Full_text'])\n",
    "t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:484: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\"The parameter 'token_pattern' will not be used\"\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:484: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\"The parameter 'token_pattern' will not be used\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1455563, 5500) (1455563, 1000)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1455563, 6500)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import nltk\n",
    "\n",
    "tfIdfVectorizer_1 = TfidfVectorizer(max_features = 5500, tokenizer=nltk.word_tokenize, use_idf=True, max_df=0.7)\n",
    "tfIdfVectorizer_2 = TfidfVectorizer(max_features = 1000, tokenizer=nltk.word_tokenize, use_idf=True)\n",
    "\n",
    "# tf_train_data = pd.concat([df_train['hashtags'], df_train['text']], axis=1)\n",
    "# df_train['ti_hash'] = tfIdfVectorizer.fit_transform(df_train['hashtags']).toarray()\n",
    "# df_train['ti_text'] = tfIdfVectorizer.fit_transform(df_train['text']).toarray()\n",
    "tfIdfVectorizer_1.fit(df_train['text'])\n",
    "tfIdfVectorizer_2.fit(df_train['hashtags'])\n",
    "\n",
    "t1 = tfIdfVectorizer_1.transform(df_train['text'])\n",
    "t2 = tfIdfVectorizer_2.transform(df_train['hashtags'])\n",
    "print(t1.shape, t2.shape)\n",
    "t = np.hstack((t1.toarray(),t2.toarray()))\n",
    "t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    t,\n",
    "    df_train['emotion'], test_size=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check label:  ['anger' 'anticipation' 'disgust' 'fear' 'joy' 'sadness' 'surprise'\n",
      " 'trust']\n",
      "\n",
      "## Before convert\n",
      "y_train[0:4]:\n",
      " 240834    disgust\n",
      "893058        joy\n",
      "588584        joy\n",
      "519950    sadness\n",
      "Name: emotion, dtype: object\n",
      "\n",
      "y_train.shape:  (1455417,)\n",
      "y_test.shape:  (146,)\n",
      "\n",
      "\n",
      "## After convert\n",
      "y_train[0:4]:\n",
      " [[0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0.]]\n",
      "\n",
      "y_train.shape:  (1455417, 8)\n",
      "y_test.shape:  (146, 8)\n"
     ]
    }
   ],
   "source": [
    "## deal with label (string -> one-hot)\n",
    "import keras\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(y_train)\n",
    "print('check label: ', label_encoder.classes_)\n",
    "print('\\n## Before convert')\n",
    "print('y_train[0:4]:\\n', y_train[0:4])\n",
    "print('\\ny_train.shape: ', y_train.shape)\n",
    "print('y_test.shape: ', y_test.shape)\n",
    "\n",
    "def label_encode(le, labels):\n",
    "    enc = le.transform(labels)\n",
    "    return keras.utils.to_categorical(enc)\n",
    "\n",
    "def label_decode(le, one_hot_label):\n",
    "    dec = np.argmax(one_hot_label, axis=1)\n",
    "    return le.inverse_transform(dec)\n",
    "\n",
    "y_train = label_encode(label_encoder, y_train)\n",
    "y_test = label_encode(label_encoder, y_test)\n",
    "\n",
    "print('\\n\\n## After convert')\n",
    "print('y_train[0:4]:\\n', y_train[0:4])\n",
    "print('\\ny_train.shape: ', y_train.shape)\n",
    "print('y_test.shape: ', y_test.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_shape:  6500\n",
      "output_shape:  8\n"
     ]
    }
   ],
   "source": [
    "# I/O check\n",
    "input_shape = X_train.shape[1]\n",
    "print('input_shape: ', input_shape)\n",
    "\n",
    "output_shape = len(label_encoder.classes_)\n",
    "print('output_shape: ', output_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_7 (InputLayer)         [(None, 6500)]            0         \n",
      "_________________________________________________________________\n",
      "dense_42 (Dense)             (None, 2048)              13314048  \n",
      "_________________________________________________________________\n",
      "re_lu_36 (ReLU)              (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_43 (Dense)             (None, 1024)              2098176   \n",
      "_________________________________________________________________\n",
      "re_lu_37 (ReLU)              (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_44 (Dense)             (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "re_lu_38 (ReLU)              (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_45 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "re_lu_39 (ReLU)              (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_46 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "re_lu_40 (ReLU)              (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_47 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "re_lu_41 (ReLU)              (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_48 (Dense)             (None, 8)                 520       \n",
      "_________________________________________________________________\n",
      "softmax_6 (Softmax)          (None, 8)                 0         \n",
      "=================================================================\n",
      "Total params: 16,110,024\n",
      "Trainable params: 16,110,024\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense\n",
    "from keras.layers import ReLU, Softmax\n",
    "import tensorflow as tf\n",
    "\n",
    "# input layer\n",
    "model_input = Input(shape=(input_shape, ))  # 500\n",
    "X = model_input\n",
    "\n",
    "# 1st hidden layer\n",
    "X_W0 = Dense(units=2048)(X)  # 64\n",
    "H0 = ReLU()(X_W0)\n",
    "\n",
    "X_W1 = Dense(units=1024)(H0)  # 64\n",
    "H1 = ReLU()(X_W1)\n",
    "\n",
    "# 2nd hidden layer\n",
    "H1_W2 = Dense(units=512)(H1)  # 64\n",
    "H2 = ReLU()(H1_W2)\n",
    "\n",
    "# output layer\n",
    "H2_W3 = Dense(units=256)(H2)  # 4\n",
    "H3 = ReLU()(H2_W3)\n",
    "\n",
    "H3_W4 = Dense(units=128)(H3)  # 4\n",
    "H4 = ReLU()(H3_W4)\n",
    "\n",
    "H4_W5 = Dense(units=64)(H4)  # 4\n",
    "H5 = ReLU()(H4_W5)\n",
    "\n",
    "H5_W6 = Dense(units=output_shape)(H5)  # 4\n",
    "H6 = Softmax()(H5_W6)\n",
    "\n",
    "model_output = H6\n",
    "\n",
    "# create model\n",
    "model = Model(inputs=[model_input], outputs=[model_output])\n",
    "\n",
    "loss = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "metric = tf.keras.metrics.SparseCategoricalAccuracy('accuracy')\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=2e-4)\n",
    "\n",
    "# loss function & optimizer\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# show model construction\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "45482/45482 [==============================] - 1581s 35ms/step - loss: 1.2193 - accuracy: 0.5598 - val_loss: 1.2825 - val_accuracy: 0.5205\n",
      "Epoch 2/5\n",
      "45482/45482 [==============================] - 1637s 36ms/step - loss: 1.0617 - accuracy: 0.6198 - val_loss: 1.2652 - val_accuracy: 0.5685\n",
      "Epoch 3/5\n",
      "45482/45482 [==============================] - 1658s 36ms/step - loss: 0.8393 - accuracy: 0.7056 - val_loss: 1.2848 - val_accuracy: 0.5753\n",
      "Epoch 4/5\n",
      "45482/45482 [==============================] - 1661s 37ms/step - loss: 0.5914 - accuracy: 0.7971 - val_loss: 1.4900 - val_accuracy: 0.5685\n",
      "Epoch 5/5\n",
      "45482/45482 [==============================] - 1657s 36ms/step - loss: 0.4158 - accuracy: 0.8599 - val_loss: 1.6946 - val_accuracy: 0.5411\n",
      "training finish\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import CSVLogger\n",
    "\n",
    "# X_train = X_train.todense()\n",
    "# X_test = X_test.todense()\n",
    "\n",
    "\n",
    "# training setting\n",
    "epochs = 5\n",
    "batch_size = 32\n",
    "\n",
    "# training!\n",
    "history = model.fit(X_train, y_train, \n",
    "                    epochs=epochs, \n",
    "                    batch_size=batch_size, \n",
    "                    validation_data = (X_test, y_test))\n",
    "print('training finish')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "## predict\n",
    "X_ans = tfIdfVectorizer_1000.transform(df_test[\"Full_text\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = tfIdfVectorizer_1.transform(df_test['text'])\n",
    "t2 = tfIdfVectorizer_2.transform(df_test['hashtags'])\n",
    "X_ans = np.hstack((t1.toarray(),t2.toarray()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.97626092e-03, 7.22786970e-03, 1.35586075e-02, 3.48014222e-03,\n",
       "        4.73394804e-02, 3.02087050e-03, 6.70580268e-01, 2.52816528e-01],\n",
       "       [1.01433034e-06, 3.72975919e-05, 1.48794579e-03, 1.19729348e-05,\n",
       "        3.33004573e-05, 9.98312473e-01, 1.11889945e-04, 4.17271031e-06],\n",
       "       [2.34003905e-02, 2.13227095e-03, 3.55986297e-01, 2.80465167e-02,\n",
       "        2.76304707e-02, 5.27450860e-01, 1.61983985e-02, 1.91547684e-02],\n",
       "       [2.65090307e-03, 6.46696790e-05, 9.95756805e-01, 3.12246964e-04,\n",
       "        2.70715536e-04, 5.14465384e-04, 3.88071378e-04, 4.20986253e-05],\n",
       "       [8.93621027e-01, 1.78704315e-04, 1.40280686e-02, 1.20199739e-03,\n",
       "        7.47758150e-02, 1.06750252e-02, 2.79533397e-03, 2.72411155e-03]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X_ans = X_ans.todense()\n",
    "pred_result = model.predict(X_ans, batch_size=128)\n",
    "pred_result[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['surprise', 'sadness', 'sadness', 'disgust', 'anger'], dtype=object)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_result = label_decode(label_encoder, pred_result)\n",
    "pred_result[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0x28cc61</td>\n",
       "      <td>surprise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0x2db41f</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0x2466f6</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0x23f9e9</td>\n",
       "      <td>disgust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0x1fb4e1</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867495</th>\n",
       "      <td>0x2c4dc2</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867496</th>\n",
       "      <td>0x31be7c</td>\n",
       "      <td>anticipation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867500</th>\n",
       "      <td>0x1ca58e</td>\n",
       "      <td>trust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867515</th>\n",
       "      <td>0x35c8ba</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867518</th>\n",
       "      <td>0x1d941b</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>411972 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         tweet_id       emotion\n",
       "0        0x28cc61      surprise\n",
       "3        0x2db41f       sadness\n",
       "15       0x2466f6       sadness\n",
       "23       0x23f9e9       disgust\n",
       "31       0x1fb4e1         anger\n",
       "...           ...           ...\n",
       "1867495  0x2c4dc2           joy\n",
       "1867496  0x31be7c  anticipation\n",
       "1867500  0x1ca58e         trust\n",
       "1867515  0x35c8ba       sadness\n",
       "1867518  0x1d941b           joy\n",
       "\n",
       "[411972 rows x 2 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test['emotion'] = pred_result\n",
    "df_answer = pd.concat([df_test['tweet_id'],\n",
    "                     df_test['emotion']], axis=1)\n",
    "df_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_answer = df_answer.rename(columns={'tweet_id':'id'})\n",
    "df_answer.to_csv('ans.csv',encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
