{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kuohuichi/opt/anaconda3/lib/python3.7/site-packages/numpy/lib/arraysetops.py:580: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1867535, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1867535, 4)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_user = pd.read_csv(\"data_identification.csv\")\n",
    "tweets = pd.read_csv(\"tweet_.csv\", lineterminator='\\n', index_col=0)\n",
    "print(all_user.shape)\n",
    "tweets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   _score                             hashtags  tweet_id  \\\n",
      "0     391                         ['Snapchat']  0x376b20   \n",
      "1     433  ['freepress', 'TrumpLegacy', 'CNN']  0x2d5350   \n",
      "2     232                       ['bibleverse']  0x28b412   \n",
      "3     376                                   []  0x1cd5b0   \n",
      "4     989                                   []  0x2de201   \n",
      "\n",
      "                                                text  \n",
      "0  People who post \"add me on #Snapchat\" must be ...  \n",
      "1  @brianklaas As we see, Trump is dangerous to #...  \n",
      "2  Confident of your obedience, I write to you, k...  \n",
      "3                Now ISSA is stalking Tasha üòÇüòÇüòÇ <LH>  \n",
      "4  \"Trust is not the same as faith. A friend is s...  \n",
      "   tweet_id identification\n",
      "0  0x28cc61           test\n",
      "1  0x29e452          train\n",
      "2  0x2b3819          train\n",
      "3  0x2db41f           test\n",
      "4  0x2a2acc          train\n"
     ]
    }
   ],
   "source": [
    "print(tweets.iloc[0:5])\n",
    "print(all_user.iloc[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>identification</th>\n",
       "      <th>_score</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0x28cc61</td>\n",
       "      <td>test</td>\n",
       "      <td>107</td>\n",
       "      <td>[]</td>\n",
       "      <td>@Habbo I've seen two separate colours of the e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0x29e452</td>\n",
       "      <td>train</td>\n",
       "      <td>809</td>\n",
       "      <td>[]</td>\n",
       "      <td>Huge Respectüñí @JohnnyVegasReal talking about l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0x2b3819</td>\n",
       "      <td>train</td>\n",
       "      <td>808</td>\n",
       "      <td>['spateradio', 'app']</td>\n",
       "      <td>Yoooo we hit all our monthly goals with the ne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0x2db41f</td>\n",
       "      <td>test</td>\n",
       "      <td>728</td>\n",
       "      <td>[]</td>\n",
       "      <td>@FoxNews @KellyannePolls No serious self respe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0x2a2acc</td>\n",
       "      <td>train</td>\n",
       "      <td>16</td>\n",
       "      <td>[]</td>\n",
       "      <td>@KIDSNTS @PICU_BCH @uhbcomms @BWCHBoss Well do...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tweet_id identification  _score               hashtags  \\\n",
       "0  0x28cc61           test     107                     []   \n",
       "1  0x29e452          train     809                     []   \n",
       "2  0x2b3819          train     808  ['spateradio', 'app']   \n",
       "3  0x2db41f           test     728                     []   \n",
       "4  0x2a2acc          train      16                     []   \n",
       "\n",
       "                                                text  \n",
       "0  @Habbo I've seen two separate colours of the e...  \n",
       "1  Huge Respectüñí @JohnnyVegasReal talking about l...  \n",
       "2  Yoooo we hit all our monthly goals with the ne...  \n",
       "3  @FoxNews @KellyannePolls No serious self respe...  \n",
       "4  @KIDSNTS @PICU_BCH @uhbcomms @BWCHBoss Well do...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_user = pd.merge(all_user,tweets, on=\"tweet_id\")\n",
    "all_user.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   tweet_id identification  _score  \\\n",
      "1  0x29e452          train     809   \n",
      "2  0x2b3819          train     808   \n",
      "4  0x2a2acc          train      16   \n",
      "5  0x2a8830          train     768   \n",
      "6  0x20b21d          train      70   \n",
      "\n",
      "                                            hashtags  \\\n",
      "1                                                 []   \n",
      "2                              ['spateradio', 'app']   \n",
      "4                                                 []   \n",
      "5  ['PUBG', 'GamersUnite', 'twitch', 'BeHealthy',...   \n",
      "6                       ['strength', 'bones', 'God']   \n",
      "\n",
      "                                                text  \n",
      "1  Huge Respectüñí @JohnnyVegasReal talking about l...  \n",
      "2  Yoooo we hit all our monthly goals with the ne...  \n",
      "4  @KIDSNTS @PICU_BCH @uhbcomms @BWCHBoss Well do...  \n",
      "5  Come join @ambushman27 on #PUBG while he striv...  \n",
      "6  @fanshixieen2014 Blessings!My #strength little...   (1455563, 5)\n",
      "    tweet_id identification  _score            hashtags  \\\n",
      "0   0x28cc61           test     107                  []   \n",
      "3   0x2db41f           test     728                  []   \n",
      "15  0x2466f6           test     491    ['womendrivers']   \n",
      "23  0x23f9e9           test      28  ['robbingmembers']   \n",
      "31  0x1fb4e1           test     925                  []   \n",
      "\n",
      "                                                 text  \n",
      "0   @Habbo I've seen two separate colours of the e...  \n",
      "3   @FoxNews @KellyannePolls No serious self respe...  \n",
      "15  Looking for a new car, and it says 1 lady owne...  \n",
      "23  @cineworld ‚Äúonly the brave‚Äù just out and fount...  \n",
      "31  Felt like total dog üí© going into open gym and ...   (411972, 5)\n"
     ]
    }
   ],
   "source": [
    "fliter = (all_user[\"identification\"] == 'train')\n",
    "df_train = all_user[fliter]\n",
    "fliter1 = (all_user[\"identification\"] == 'test')\n",
    "df_test = all_user[fliter1]\n",
    "print(df_train.head(), df_train.shape)\n",
    "print(df_test.head(), df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>identification</th>\n",
       "      <th>_score</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>text</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0x20b21d</td>\n",
       "      <td>train</td>\n",
       "      <td>70</td>\n",
       "      <td>['strength', 'bones', 'God']</td>\n",
       "      <td>@fanshixieen2014 Blessings!My #strength little...</td>\n",
       "      <td>anticipation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0x2452cf</td>\n",
       "      <td>train</td>\n",
       "      <td>909</td>\n",
       "      <td>['MondayMotivation']</td>\n",
       "      <td>Never give up. The manifestation of your goal ...</td>\n",
       "      <td>anticipation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0x2d729d</td>\n",
       "      <td>train</td>\n",
       "      <td>769</td>\n",
       "      <td>['DreamsComeTrue']</td>\n",
       "      <td>I Believe When No One Else Does... &lt;LH&gt; #Dream...</td>\n",
       "      <td>anticipation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0x2ab56d</td>\n",
       "      <td>train</td>\n",
       "      <td>574</td>\n",
       "      <td>['JustAsking', 'Love']</td>\n",
       "      <td>@SirPareshRawal with due respect... Do u have ...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0x1f3657</td>\n",
       "      <td>train</td>\n",
       "      <td>877</td>\n",
       "      <td>['help']</td>\n",
       "      <td>I can't tell if I'm alive or in the after life...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95</td>\n",
       "      <td>0x28ca95</td>\n",
       "      <td>train</td>\n",
       "      <td>502</td>\n",
       "      <td>['8weekstogo']</td>\n",
       "      <td>Aw work arranged me a baby shower üíôüëåüèºüë∂üèºüçº &lt;LH&gt; ...</td>\n",
       "      <td>trust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96</td>\n",
       "      <td>0x214f52</td>\n",
       "      <td>train</td>\n",
       "      <td>52</td>\n",
       "      <td>[]</td>\n",
       "      <td>Chester Pride is absolutely off the scale this...</td>\n",
       "      <td>trust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>97</td>\n",
       "      <td>0x2e5957</td>\n",
       "      <td>train</td>\n",
       "      <td>383</td>\n",
       "      <td>[]</td>\n",
       "      <td>Happy thanksgiving to everyone!! üçÅü¶É Hope you e...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>98</td>\n",
       "      <td>0x2811a1</td>\n",
       "      <td>train</td>\n",
       "      <td>29</td>\n",
       "      <td>[]</td>\n",
       "      <td>@washingtonpost yawwwwn.... More propaganda fr...</td>\n",
       "      <td>anticipation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>99</td>\n",
       "      <td>0x2c9299</td>\n",
       "      <td>train</td>\n",
       "      <td>582</td>\n",
       "      <td>['Hair', 'Business', 'Dedication']</td>\n",
       "      <td>Starting my &lt;LH&gt; #Hair #Business gets overwhel...</td>\n",
       "      <td>trust</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>96 rows √ó 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    tweet_id identification  _score                            hashtags  \\\n",
       "4   0x20b21d          train      70        ['strength', 'bones', 'God']   \n",
       "5   0x2452cf          train     909                ['MondayMotivation']   \n",
       "6   0x2d729d          train     769                  ['DreamsComeTrue']   \n",
       "7   0x2ab56d          train     574              ['JustAsking', 'Love']   \n",
       "8   0x1f3657          train     877                            ['help']   \n",
       "..       ...            ...     ...                                 ...   \n",
       "95  0x28ca95          train     502                      ['8weekstogo']   \n",
       "96  0x214f52          train      52                                  []   \n",
       "97  0x2e5957          train     383                                  []   \n",
       "98  0x2811a1          train      29                                  []   \n",
       "99  0x2c9299          train     582  ['Hair', 'Business', 'Dedication']   \n",
       "\n",
       "                                                 text       emotion  \n",
       "4   @fanshixieen2014 Blessings!My #strength little...  anticipation  \n",
       "5   Never give up. The manifestation of your goal ...  anticipation  \n",
       "6   I Believe When No One Else Does... <LH> #Dream...  anticipation  \n",
       "7   @SirPareshRawal with due respect... Do u have ...           joy  \n",
       "8   I can't tell if I'm alive or in the after life...       sadness  \n",
       "..                                                ...           ...  \n",
       "95  Aw work arranged me a baby shower üíôüëåüèºüë∂üèºüçº <LH> ...         trust  \n",
       "96  Chester Pride is absolutely off the scale this...         trust  \n",
       "97  Happy thanksgiving to everyone!! üçÅü¶É Hope you e...           joy  \n",
       "98  @washingtonpost yawwwwn.... More propaganda fr...  anticipation  \n",
       "99  Starting my <LH> #Hair #Business gets overwhel...         trust  \n",
       "\n",
       "[96 rows x 6 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emotion = pd.read_csv(\"emotion.csv\")\n",
    "df_train = pd.merge(df_train,emotion, on=\"tweet_id\")\n",
    "df_train.iloc[4:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1455563 entries, 0 to 1455562\n",
      "Data columns (total 6 columns):\n",
      "tweet_id          1455563 non-null object\n",
      "identification    1455563 non-null object\n",
      "_score            1455563 non-null int64\n",
      "hashtags          1455563 non-null object\n",
      "text              1455563 non-null object\n",
      "emotion           1455563 non-null object\n",
      "dtypes: int64(1), object(5)\n",
      "memory usage: 77.7+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tweet_id          0\n",
       "identification    0\n",
       "_score            0\n",
       "hashtags          0\n",
       "text              0\n",
       "emotion           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.info()\n",
    "df_train.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>_score</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>text</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0x29e452</td>\n",
       "      <td>809</td>\n",
       "      <td>[]</td>\n",
       "      <td>Huge Respectüñí @JohnnyVegasReal talking about l...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0x2b3819</td>\n",
       "      <td>808</td>\n",
       "      <td>['spateradio', 'app']</td>\n",
       "      <td>Yoooo we hit all our monthly goals with the ne...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0x2a2acc</td>\n",
       "      <td>16</td>\n",
       "      <td>[]</td>\n",
       "      <td>@KIDSNTS @PICU_BCH @uhbcomms @BWCHBoss Well do...</td>\n",
       "      <td>trust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0x2a8830</td>\n",
       "      <td>768</td>\n",
       "      <td>['PUBG', 'GamersUnite', 'twitch', 'BeHealthy',...</td>\n",
       "      <td>Come join @ambushman27 on #PUBG while he striv...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0x20b21d</td>\n",
       "      <td>70</td>\n",
       "      <td>['strength', 'bones', 'God']</td>\n",
       "      <td>@fanshixieen2014 Blessings!My #strength little...</td>\n",
       "      <td>anticipation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tweet_id  _score                                           hashtags  \\\n",
       "0  0x29e452     809                                                 []   \n",
       "1  0x2b3819     808                              ['spateradio', 'app']   \n",
       "2  0x2a2acc      16                                                 []   \n",
       "3  0x2a8830     768  ['PUBG', 'GamersUnite', 'twitch', 'BeHealthy',...   \n",
       "4  0x20b21d      70                       ['strength', 'bones', 'God']   \n",
       "\n",
       "                                                text       emotion  \n",
       "0  Huge Respectüñí @JohnnyVegasReal talking about l...           joy  \n",
       "1  Yoooo we hit all our monthly goals with the ne...           joy  \n",
       "2  @KIDSNTS @PICU_BCH @uhbcomms @BWCHBoss Well do...         trust  \n",
       "3  Come join @ambushman27 on #PUBG while he striv...           joy  \n",
       "4  @fanshixieen2014 Blessings!My #strength little...  anticipation  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = df_train.drop(columns=['identification'],axis=1)\n",
    "df_test = df_test.drop(columns=['identification'],axis=1)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "list_hash = df_train['hashtags'].tolist()\n",
    "for i in range(len(list_hash)):\n",
    "    if len(list_hash[i]) == 0:\n",
    "        list_hash[i]=None\n",
    "    else:\n",
    "        list_hash[i]=list_hash[i][1:len(list_hash[i])-2]\n",
    "        list_hash[i] = [word.strip(string.punctuation) for word in list_hash[i].split(\", \")]\n",
    "        list_hash[i] = ' '.join(list_hash[i])\n",
    "df_train['hashtags'] = list_hash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>_score</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>text</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0x29e452</td>\n",
       "      <td>809</td>\n",
       "      <td></td>\n",
       "      <td>Huge Respectüñí @JohnnyVegasReal talking about l...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0x2b3819</td>\n",
       "      <td>808</td>\n",
       "      <td>spateradio app</td>\n",
       "      <td>Yoooo we hit all our monthly goals with the ne...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0x2a2acc</td>\n",
       "      <td>16</td>\n",
       "      <td></td>\n",
       "      <td>@KIDSNTS @PICU_BCH @uhbcomms @BWCHBoss Well do...</td>\n",
       "      <td>trust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0x2a8830</td>\n",
       "      <td>768</td>\n",
       "      <td>PUBG GamersUnite twitch BeHealthy StayPositive...</td>\n",
       "      <td>Come join @ambushman27 on #PUBG while he striv...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0x20b21d</td>\n",
       "      <td>70</td>\n",
       "      <td>strength bones God</td>\n",
       "      <td>@fanshixieen2014 Blessings!My #strength little...</td>\n",
       "      <td>anticipation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tweet_id  _score                                           hashtags  \\\n",
       "0  0x29e452     809                                                      \n",
       "1  0x2b3819     808                                     spateradio app   \n",
       "2  0x2a2acc      16                                                      \n",
       "3  0x2a8830     768  PUBG GamersUnite twitch BeHealthy StayPositive...   \n",
       "4  0x20b21d      70                                 strength bones God   \n",
       "\n",
       "                                                text       emotion  \n",
       "0  Huge Respectüñí @JohnnyVegasReal talking about l...           joy  \n",
       "1  Yoooo we hit all our monthly goals with the ne...           joy  \n",
       "2  @KIDSNTS @PICU_BCH @uhbcomms @BWCHBoss Well do...         trust  \n",
       "3  Come join @ambushman27 on #PUBG while he striv...           joy  \n",
       "4  @fanshixieen2014 Blessings!My #strength little...  anticipation  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import nltk\n",
    "\n",
    "tfIdfVectorizer_1 = TfidfVectorizer(max_features = 800, tokenizer=nltk.word_tokenize, use_idf=True)\n",
    "tfIdfVectorizer_2 = TfidfVectorizer(max_features = 800, tokenizer=nltk.word_tokenize, use_idf=True)\n",
    "\n",
    "# tf_train_data = pd.concat([df_train['hashtags'], df_train['text']], axis=1)\n",
    "# df_train['ti_hash'] = tfIdfVectorizer.fit_transform(df_train['hashtags']).toarray()\n",
    "# df_train['ti_text'] = tfIdfVectorizer.fit_transform(df_train['text']).toarray()\n",
    "tfIdfVectorizer_1.fit(df_train['text'])\n",
    "tfIdfVectorizer_2.fit(df_train['hashtags'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = tfIdfVectorizer_1.transform(df_train['text'])\n",
    "t1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t2 = tfIdfVectorizer_2.transform(df_train['hashtags'])\n",
    "t2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t2.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = np.hstack((t1.toarray(),t2.toarray()))\n",
    "t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    t,\n",
    "    df_train['emotion'], test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1164450, 1600)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'lower'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-74-f89d391be969>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtfIdfVectorizer_500\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# y_train = df_train['emotion']\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtfIdfVectorizer_500\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# y_test = df_test['emotion']\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, raw_documents, copy)\u001b[0m\n\u001b[1;32m   1639\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_tfidf'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'The tfidf vector is not fitted'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1641\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTfidfVectorizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_documents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1642\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tfidf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, raw_documents)\u001b[0m\n\u001b[1;32m   1083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m         \u001b[0;31m# use the same matrix-building strategy as fit_transform\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1085\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_count_vocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_documents\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfixed_vocab\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1086\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1087\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfill\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m_count_vocab\u001b[0;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[1;32m    941\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mraw_documents\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    942\u001b[0m             \u001b[0mfeature_counter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 943\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mfeature\u001b[0m \u001b[0;32min\u001b[0m \u001b[0manalyze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    944\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    945\u001b[0m                     \u001b[0mfeature_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(doc)\u001b[0m\n\u001b[1;32m    327\u001b[0m                                                tokenize)\n\u001b[1;32m    328\u001b[0m             return lambda doc: self._word_ngrams(\n\u001b[0;32m--> 329\u001b[0;31m                 tokenize(preprocess(self.decode(doc))), stop_words)\n\u001b[0m\u001b[1;32m    330\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlowercase\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstrip_accents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mstrip_accents\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'lower'"
     ]
    }
   ],
   "source": [
    "X_train = tfIdfVectorizer_500.transform(X_train).toarray()\n",
    "# y_train = df_train['emotion']\n",
    "\n",
    "X_test = tfIdfVectorizer_500.transform(X_test).toarray()\n",
    "# y_test = df_test['emotion']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "NB_model = GaussianNB()\n",
    "NB_model = NB_model.fit(X_train, y_train)\n",
    "\n",
    "y_train_pred = NB_model.predict(X_train)\n",
    "y_test_pred = NB_model.predict(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "RF = RandomForestClassifier(n_estimators=100, random_state=0)\n",
    "RF = RF.fit(X_train, y_train)\n",
    "\n",
    "y_train_pred = RF.predict(X_train)\n",
    "y_test_pred = RF.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "acc_train = accuracy_score(y_true=y_train, y_pred=y_train_pred)\n",
    "acc_test = accuracy_score(y_true=y_test, y_pred=y_test_pred)\n",
    "\n",
    "print('training accuracy: {}'.format(round(acc_train, 2)))\n",
    "print('testing accuracy: {}'.format(round(acc_test, 2)))\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_true=y_test, y_pred=y_test_pred))\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(y_true=y_test, y_pred=y_test_pred) \n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ans = tfIdfVectorizer_500.transform(df_test['text']).toarray()\n",
    "y_ans = RF.predict(X_ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0x28cc61</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0x2db41f</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0x2466f6</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0x23f9e9</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>0x1fb4e1</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1867495</td>\n",
       "      <td>0x2c4dc2</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1867496</td>\n",
       "      <td>0x31be7c</td>\n",
       "      <td>anticipation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1867500</td>\n",
       "      <td>0x1ca58e</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1867515</td>\n",
       "      <td>0x35c8ba</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1867518</td>\n",
       "      <td>0x1d941b</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>411972 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         tweet_id       emotion\n",
       "0        0x28cc61       sadness\n",
       "3        0x2db41f           joy\n",
       "15       0x2466f6           joy\n",
       "23       0x23f9e9           joy\n",
       "31       0x1fb4e1           joy\n",
       "...           ...           ...\n",
       "1867495  0x2c4dc2           joy\n",
       "1867496  0x31be7c  anticipation\n",
       "1867500  0x1ca58e           joy\n",
       "1867515  0x35c8ba           joy\n",
       "1867518  0x1d941b           joy\n",
       "\n",
       "[411972 rows x 2 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test['emotion'] = y_ans\n",
    "df_answer = pd.concat([df_test['tweet_id'],\n",
    "                     df_test['emotion']], axis=1)\n",
    "df_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_answer = df_answer.rename(columns={'tweet_id':'id'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_answer.to_csv('ans.csv',encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funciton for visualizing confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import itertools\n",
    "\n",
    "def plot_confusion_matrix(cm, classes, title='Confusion matrix',\n",
    "                          cmap=sns.cubehelix_palette(as_cmap=True)):\n",
    "    \"\"\"\n",
    "    This function is modified from: \n",
    "    http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n",
    "    \"\"\"\n",
    "    classes.sort()\n",
    "    tick_marks = np.arange(len(classes))    \n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(15,15))\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    ax.set(xticks=np.arange(cm.shape[1]),\n",
    "           yticks=np.arange(cm.shape[0]),\n",
    "           xticklabels = classes,\n",
    "           yticklabels = classes,\n",
    "           title = title,\n",
    "           xlabel = 'True label',\n",
    "           ylabel = 'Predicted label')\n",
    "\n",
    "    fmt = 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt), horizontalalignment=\"center\", color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    ylim_top = len(classes) - 0.5\n",
    "    plt.ylim([ylim_top, -.5])\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_tags = ['anger', 'fear', 'joy', 'sadness']\n",
    "plot_confusion_matrix(cm, classes=my_tags, title='Confusion matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_score</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>391</td>\n",
       "      <td>[Snapchat]</td>\n",
       "      <td>0x376b20</td>\n",
       "      <td>People who post \"add me on #Snapchat\" must be ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>433</td>\n",
       "      <td>[freepress, TrumpLegacy, CNN]</td>\n",
       "      <td>0x2d5350</td>\n",
       "      <td>@brianklaas As we see, Trump is dangerous to #...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>232</td>\n",
       "      <td>[bibleverse]</td>\n",
       "      <td>0x28b412</td>\n",
       "      <td>Confident of your obedience, I write to you, k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>376</td>\n",
       "      <td>[]</td>\n",
       "      <td>0x1cd5b0</td>\n",
       "      <td>Now ISSA is stalking Tasha üòÇüòÇüòÇ &lt;LH&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>989</td>\n",
       "      <td>[]</td>\n",
       "      <td>0x2de201</td>\n",
       "      <td>\"Trust is not the same as faith. A friend is s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   _score                       hashtags  tweet_id  \\\n",
       "0     391                     [Snapchat]  0x376b20   \n",
       "1     433  [freepress, TrumpLegacy, CNN]  0x2d5350   \n",
       "2     232                   [bibleverse]  0x28b412   \n",
       "3     376                             []  0x1cd5b0   \n",
       "4     989                             []  0x2de201   \n",
       "\n",
       "                                                text  \n",
       "0  People who post \"add me on #Snapchat\" must be ...  \n",
       "1  @brianklaas As we see, Trump is dangerous to #...  \n",
       "2  Confident of your obedience, I write to you, k...  \n",
       "3                Now ISSA is stalking Tasha üòÇüòÇüòÇ <LH>  \n",
       "4  \"Trust is not the same as faith. A friend is s...  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###tweet\n",
    "tweets = pd.read_json('tweets_DM.json', lines=True)\n",
    "tweets.head()\n",
    "print(tweets['_type'].value_counts())\n",
    "print(tweets['_index'].value_counts())\n",
    "tweets = tweets.drop(columns=['_type', '_index', '_crawldate'],axis=1)\n",
    "tweets['tweets'] = tweets['_source'].apply(pd.Series)\n",
    "tweets = pd.concat([tweets['_score'],\n",
    "                     tweets['tweets'].apply(pd.Series)], axis=1)\n",
    "tweets.head()\n",
    "tweets.to_csv('tweet_.csv',encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
